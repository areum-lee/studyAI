{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('predict (before training)', 4, 4.0)\n",
      "('\\tgrad: ', 1.0, 2.0, -2.0)\n",
      "('\\tgrad: ', 2.0, 4.0, -7.84)\n",
      "('\\tgrad: ', 3.0, 6.0, -16.23)\n",
      "('progress:', 0, 'w=', 1.26, 'loss=', 4.92)\n",
      "('\\tgrad: ', 1.0, 2.0, -1.48)\n",
      "('\\tgrad: ', 2.0, 4.0, -5.8)\n",
      "('\\tgrad: ', 3.0, 6.0, -12.0)\n",
      "('progress:', 1, 'w=', 1.45, 'loss=', 2.69)\n",
      "('\\tgrad: ', 1.0, 2.0, -1.09)\n",
      "('\\tgrad: ', 2.0, 4.0, -4.29)\n",
      "('\\tgrad: ', 3.0, 6.0, -8.87)\n",
      "('progress:', 2, 'w=', 1.6, 'loss=', 1.47)\n",
      "('\\tgrad: ', 1.0, 2.0, -0.81)\n",
      "('\\tgrad: ', 2.0, 4.0, -3.17)\n",
      "('\\tgrad: ', 3.0, 6.0, -6.56)\n",
      "('progress:', 3, 'w=', 1.7, 'loss=', 0.8)\n",
      "('\\tgrad: ', 1.0, 2.0, -0.6)\n",
      "('\\tgrad: ', 2.0, 4.0, -2.34)\n",
      "('\\tgrad: ', 3.0, 6.0, -4.85)\n",
      "('progress:', 4, 'w=', 1.78, 'loss=', 0.44)\n",
      "('\\tgrad: ', 1.0, 2.0, -0.44)\n",
      "('\\tgrad: ', 2.0, 4.0, -1.73)\n",
      "('\\tgrad: ', 3.0, 6.0, -3.58)\n",
      "('progress:', 5, 'w=', 1.84, 'loss=', 0.24)\n",
      "('\\tgrad: ', 1.0, 2.0, -0.33)\n",
      "('\\tgrad: ', 2.0, 4.0, -1.28)\n",
      "('\\tgrad: ', 3.0, 6.0, -2.65)\n",
      "('progress:', 6, 'w=', 1.88, 'loss=', 0.13)\n",
      "('\\tgrad: ', 1.0, 2.0, -0.24)\n",
      "('\\tgrad: ', 2.0, 4.0, -0.95)\n",
      "('\\tgrad: ', 3.0, 6.0, -1.96)\n",
      "('progress:', 7, 'w=', 1.91, 'loss=', 0.07)\n",
      "('\\tgrad: ', 1.0, 2.0, -0.18)\n",
      "('\\tgrad: ', 2.0, 4.0, -0.7)\n",
      "('\\tgrad: ', 3.0, 6.0, -1.45)\n",
      "('progress:', 8, 'w=', 1.93, 'loss=', 0.04)\n",
      "('\\tgrad: ', 1.0, 2.0, -0.13)\n",
      "('\\tgrad: ', 2.0, 4.0, -0.52)\n",
      "('\\tgrad: ', 3.0, 6.0, -1.07)\n",
      "('progress:', 9, 'w=', 1.95, 'loss=', 0.02)\n",
      "('predict (after training)', '4 hours', 7.804863933862125)\n"
     ]
    }
   ],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = 1.0  # a random guess: random value\n",
    "\n",
    "# our model forward pass\n",
    "\n",
    "\n",
    "def forward(x,w):\n",
    "    return x * w\n",
    "\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y,w):\n",
    "    y_pred = forward(x,w)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "\n",
    "# compute gradient\n",
    "def gradient(x, y):  # d_loss/d_w\n",
    "    return 2 * x * (x * w - y)\n",
    "\n",
    "# Before training\n",
    "print(\"predict (before training)\",  4, forward(4,w))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad = gradient(x_val, y_val)\n",
    "        \n",
    "        # 업데이트\n",
    "        # 0.01 을 learning rate라고 부른다.\n",
    "        w = w - 0.01 * grad\n",
    "        print(\"\\tgrad: \", x_val, y_val, round(grad, 2))\n",
    "        l = loss(x_val, y_val,w)\n",
    "\n",
    "    print(\"progress:\", epoch, \"w=\", round(w, 2), \"loss=\", round(l, 2))\n",
    "\n",
    "# After training\n",
    "print(\"predict (after training)\",  \"4 hours\", forward(4,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('progress', 0, 'w', 1.26, ' loss', 4.92)\n",
      "('progress', 1, 'w', 1.45, ' loss', 2.69)\n",
      "('progress', 2, 'w', 1.6, ' loss', 1.47)\n",
      "('progress', 3, 'w', 1.7, ' loss', 0.8)\n",
      "('progress', 4, 'w', 1.78, ' loss', 0.44)\n",
      "('progress', 5, 'w', 1.84, ' loss', 0.24)\n",
      "('progress', 6, 'w', 1.88, ' loss', 0.13)\n",
      "('progress', 7, 'w', 1.91, ' loss', 0.07)\n",
      "('progress', 8, 'w', 1.93, ' loss', 0.04)\n",
      "('progress', 9, 'w', 1.95, ' loss', 0.02)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w=1.0\n",
    "def gradient2(x,y,w):\n",
    "    return 2*x*(x*w-y)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad = gradient2(x_val,y_val,w)\n",
    "        \n",
    "        w = w - 0.01*grad\n",
    "        l = loss ( x_val, y_val,w)\n",
    "        \n",
    "        # 반올림 round(w,2)   2번째 자리 수에서 반올림\n",
    "        \n",
    "    print (\"progress\", epoch, \"w\" , round(w,2) , \" loss\" , round(l,2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
